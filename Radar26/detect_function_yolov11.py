# å¯¼å…¥éœ€è¦çš„åº“
import os
import sys
import time
from pathlib import Path
import cv2
import random
import torch
import numpy as np
from ultralytics import YOLO
from ultralytics.engine.results import Results


FILE = Path(__file__).resolve()
ROOT = FILE.parents[0]
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))
ROOT = Path(os.path.relpath(ROOT, Path.cwd()))


class YOLOv11Detector:
    def __init__(self, weights_path, img_size=640, conf_thres=0.70, iou_thres=0.2, max_det=10,
                 device='', classes=None, augment=False, visualize=False, half=True, data='coco8.yaml', ui=False):
        """
        YOLOv11æ£€æµ‹å™¨åˆå§‹åŒ–ï¼ˆåŒ…å«å®Œæ•´é¢„å¤„ç†ï¼‰
        """
        self.ui = ui
        self.device = device if device else ('cuda' if torch.cuda.is_available() else 'cpu')

        # åŠ è½½YOLOv11æ¨¡å‹
        try:
            self.model = YOLO(weights_path)
            print(f"âœ… YOLOv11æ¨¡å‹åŠ è½½æˆåŠŸ: {weights_path}")
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise

        # è®¾ç½®æ¨¡å‹å‚æ•°
        self.model.overrides['conf'] = conf_thres
        self.model.overrides['iou'] = iou_thres
        self.model.overrides['agnostic_nms'] = False
        self.model.overrides['max_det'] = max_det
        self.model.overrides['classes'] = classes
        self.model.overrides['augment'] = augment
        self.model.overrides['verbose'] = False

        # è·å–ç±»åˆ«åç§°
        self.names = self.model.names
        self.colors = [[random.randint(0, 255) for _ in range(3)] for _ in self.names]

        self.img_size = img_size
        self.conf_thres = conf_thres
        self.iou_thres = iou_thres
        self.max_det = max_det
        self.classes = classes
        self.augment = augment
        self.visualize = visualize
        self.half = half and self.device != 'cpu'

        if self.half:
            self.model.model.half()

        print(f"ğŸ¯ æ¨¡å‹åˆå§‹åŒ–å®Œæˆ: è®¾å¤‡={self.device}, å°ºå¯¸={img_size}, åŠç²¾åº¦={self.half}")

    def _preprocess_image(self, img):
        """
        æ‰‹åŠ¨å›¾åƒé¢„å¤„ç†ï¼ˆç±»ä¼¼YOLOv5çš„letterboxå¤„ç†ï¼‰
        """
        # ä¿å­˜åŸå§‹å›¾åƒ
        im0 = img.copy()

        # è·å–æ¨¡å‹æœŸæœ›çš„è¾“å…¥å°ºå¯¸
        if hasattr(self.model, 'model'):
            # ä»æ¨¡å‹é…ç½®è·å–å°ºå¯¸
            model_cfg = self.model.model.args if hasattr(self.model.model, 'args') else {}
            imgsz = model_cfg.get('imgsz', self.img_size)
        else:
            imgsz = self.img_size

        # ä½¿ç”¨letterboxè¿›è¡Œé¢„å¤„ç†ï¼ˆä¿æŒå®½é«˜æ¯”çš„resize + paddingï¼‰
        im, ratio, (dw, dh) = self.letterbox(im0, new_shape=(imgsz, imgsz), auto=False, scaleup=True)

        # BGR to RGB
        im = im[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, HWC to CHW
        im = np.ascontiguousarray(im)

        # è½¬æ¢ä¸ºtensorå¹¶å½’ä¸€åŒ–
        im = torch.from_numpy(im).to(self.device)
        im = im.half() if self.half else im.float()
        im /= 255.0  # å½’ä¸€åŒ– 0-255 to 0.0-1.0

        if len(im.shape) == 3:
            im = im.unsqueeze(0)  # æ·»åŠ batchç»´åº¦

        return im, im0, ratio, (dw, dh)

    def letterbox(self, im, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleup=True, stride=32):
        # è°ƒæ•´å›¾åƒå°ºå¯¸å¹¶ä¿æŒå®½é«˜æ¯”
        shape = im.shape[:2]  # å½“å‰å°ºå¯¸ [height, width]
        if isinstance(new_shape, int):
            new_shape = (new_shape, new_shape)

        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
        r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])
        if not scaleup:  # åªç¼©å°ä¸æ”¾å¤§
            r = min(r, 1.0)

        # è®¡ç®—æ–°çš„æœªå¡«å……å°ºå¯¸
        new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))
        dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding

        if auto:  # æœ€å°çŸ©å½¢
            dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding

        # åˆ†å‰²paddingåˆ°ä¸¤ä¾§
        dw /= 2
        dh /= 2

        if shape[::-1] != new_unpad:  # è°ƒæ•´å°ºå¯¸
            im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)

        top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))
        left, right = int(round(dw - 0.1)), int(round(dw + 0.1))
        im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # æ·»åŠ è¾¹æ¡†

        return im, r, (dw, dh)

    def _scale_coords(self, img1_shape, coords, img0_shape, ratio_pad=None):
        """
        å°†åæ ‡ä»é¢„å¤„ç†åçš„å›¾åƒå°ºå¯¸æ˜ å°„å›åŸå§‹å›¾åƒå°ºå¯¸
        """
        if ratio_pad is None:  # è®¡ç®—æ¯”ä¾‹
            gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])  # gain = old / new
            pad = (img1_shape[1] - img0_shape[1] * gain) / 2, (img1_shape[0] - img0_shape[0] * gain) / 2  # wh padding
        else:
            gain = ratio_pad[0][0]
            pad = ratio_pad[1]

        coords[:, [0, 2]] -= pad[0]  # x padding
        coords[:, [1, 3]] -= pad[1]  # y padding
        coords[:, :4] /= gain

        # è£å‰ªåˆ°å›¾åƒè¾¹ç•Œå†…
        coords[:, [0, 2]] = coords[:, [0, 2]].clip(0, img0_shape[1])  # xè½´
        coords[:, [1, 3]] = coords[:, [1, 3]].clip(0, img0_shape[0])  # yè½´
        return coords

    def predict(self, img):
        """
        æ‰§è¡Œç›®æ ‡æ£€æµ‹æ¨ç†ï¼ˆåŒ…å«å®Œæ•´é¢„å¤„ç†ï¼‰
        """
        try:
            # æ–¹æ³•1: ä½¿ç”¨Ultralyticså†…ç½®é¢„å¤„ç†ï¼ˆæ¨èï¼‰
            results = self.model.predict(
                img,
                imgsz=self.img_size,
                conf=self.conf_thres,
                iou=self.iou_thres,
                classes=self.classes,
                max_det=self.max_det,
                augment=self.augment,
                verbose=False
            )

            detections = []

            for r in results:
                boxes = r.boxes
                if boxes is not None and len(boxes) > 0:
                    for i, box in enumerate(boxes):
                        # è·å–åæ ‡ (xyxyæ ¼å¼)
                        xyxy = box.xyxy[0].cpu().numpy()
                        x1, y1, x2, y2 = xyxy
                        w, h = x2 - x1, y2 - y1
                        xywh = [int(x1), int(y1), int(w), int(h)]

                        # è·å–ç½®ä¿¡åº¦å’Œç±»åˆ«
                        conf = float(box.conf[0].cpu().numpy())
                        cls = int(box.cls[0].cpu().numpy())
                        class_name = self.names[cls]

                        # å¦‚æœç”¨äºUIç•Œé¢ï¼Œç»˜åˆ¶æ£€æµ‹ç»“æœ
                        if self.ui:
                            self._draw_detection(img, xyxy, class_name, conf, cls)

                        line = (class_name, xywh, conf)
                        detections.append(line)

            return detections

        except Exception as e:
            print(f"âŒ æ¨ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return []

    def predict_manual_preprocess(self, img):
        try:
            # æ‰‹åŠ¨é¢„å¤„ç†
            im, im0, ratio, pad = self._preprocess_image(img)

            # æ¨ç†
            with torch.no_grad():
                pred = self.model.model(im)  # ç›´æ¥è°ƒç”¨æ¨¡å‹

            # åå¤„ç†ï¼ˆéœ€è¦æ ¹æ®å…·ä½“æ¨¡å‹è¾“å‡ºæ ¼å¼è°ƒæ•´ï¼‰
            # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…éœ€è¦æ ¹æ®YOLOv11çš„è¾“å‡ºæ ¼å¼è¿›è¡ŒNMSç­‰æ“ä½œ
            detections = self._process_predictions(pred, im0.shape, ratio, pad)

            return detections

        except Exception as e:
            print(f"âŒ æ‰‹åŠ¨é¢„å¤„ç†æ¨ç†å‡ºé”™: {e}")
            return []

    def _process_predictions(self, pred, orig_shape, ratio, pad):
        """
        å¤„ç†æ¨¡å‹åŸå§‹è¾“å‡º
        """
        # è¿™é‡Œéœ€è¦æ ¹æ®YOLOv11çš„å®é™…è¾“å‡ºæ ¼å¼è¿›è¡Œè§£æ
        # åŒ…æ‹¬NMSã€åæ ‡æ˜ å°„ç­‰æ“ä½œ
        detections = []
        # å®ç°ç»†èŠ‚éœ€è¦æ ¹æ®å…·ä½“æ¨¡å‹è°ƒæ•´
        return detections

    def _draw_detection(self, img, xyxy, class_name, conf, cls):
        """ç»˜åˆ¶æ£€æµ‹æ¡†å’Œæ ‡ç­¾"""
        x1, y1, x2, y2 = map(int, xyxy)

        # ç»˜åˆ¶è¾¹ç•Œæ¡†
        color = self.colors[cls]
        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)

        # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
        label = f'{class_name} {conf:.2f}'
        label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]

        cv2.rectangle(img, (x1, y1 - label_size[1] - 10),
                      (x1 + label_size[0], y1), color, -1)

        # ç»˜åˆ¶æ ‡ç­¾æ–‡æœ¬
        cv2.putText(img, label, (x1, y1 - 5),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)

